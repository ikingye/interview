'use strict';(function(){const b={cache:!0};b.doc={id:'id',field:['title','content'],store:['title','href','section']};const a=FlexSearch.create('balance',b);window.bookSearchIndex=a,a.add({id:0,href:'/interview/docs/os/',title:"2. 操作系统",section:"Docs",content:"操作系统 #  进程 #  一个进程包含哪些信息？ #   进程切换时，操作系统做了哪些事情？ #   进程切换时，需要保存哪些信息，保存在哪里？ #   线程 #  线程比进程轻量，体现在哪里？ #   什么时候使用线程，什么时候使用进程？ #   携程 #  协程是什么，怎么实现的？ #   既然协程那么好，那什么时候用进程和线程？ #  程序加载的时候，是怎么分布的，哪些在堆里，哪些在栈里？ #  "}),a.add({id:1,href:'/interview/docs/network/',title:"3. 网络",section:"Docs",content:"网络 #  "}),a.add({id:2,href:'/interview/docs/algs/',title:"4. 数据结构与算法",section:"Docs",content:"数据结构与算法 #  "}),a.add({id:3,href:'/interview/docs/pl/',title:"5. 编程语言",section:"Docs",content:"编程语言 #  "}),a.add({id:4,href:'/interview/docs/os/linux/',title:"Linux",section:"2. 操作系统",content:"Linux #  更多教程详见：Linux 学习笔记  硬件信息 #  如何查看内存大小？ #  free -m 如何查看 CPU 个数，CPU 核心数，逻辑 CPU 个数？ #  # 物理 cpu 个数 cat /proc/cpuinfo| grep \u0026#39;physical id\u0026#39; | sort | uniq | wc -l # 每个物理 cpu 的核心数 cat /proc/cpuinfo| grep \u0026#39;core id\u0026#39; | sort | uniq | wc -l # 逻辑 cpu 个数（线程数） cat /proc/cpuinfo| grep \u0026#39;processor\u0026#39; | sort | uniq | wc -l 例子：\n 2 个 cpu 每个 cpu 有 8 个核心（一共 16 个核心） 一共有 32 个逻辑 cpu / 线程（每个核心有 2 个逻辑 cpu / 线程）   如何查看系统内核？ #  uname -a cat /proc/version 如何查看操作系统版本？ #  cat /etc/issue cat /etc/*release  运行信息 #  如何查看占用内存最多的进程？ #  如何查看占用 CPU 最多的进程？ #  如何查看占用某个端口的进程？ #  如何查看文件被占用没被彻底删除（看不到文件，但是磁盘没有释放）？ #  lsof |grep deleted\nps #  ps aux 与 ps -ef 有什么区别？ #   lsof #  awk #  sed #  "}),a.add({id:5,href:'/interview/docs/se/',title:"6. 软件工程",section:"Docs",content:"软件工程 #  "}),a.add({id:6,href:'/interview/docs/cloud/',title:"7. 云计算",section:"Docs",content:"云计算 #  "}),a.add({id:7,href:'/interview/docs/bigdata/',title:"8. 大数据",section:"Docs",content:"大数据 #  "}),a.add({id:8,href:'/interview/docs/ai/',title:"9. 人工智能",section:"Docs",content:"人工智能 #   AI means getting a computer to mimic human behavior in some way. Machine Learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications. Deep Learning is a subset of machine learning that enables computers to solve more complex problems.  参考：\n What\u0026rsquo;s the Difference Between AI, Machine Learning, and Deep Learning? What’s the Difference Between Artificial Intelligence, Machine Learning and Deep Learning?  "}),a.add({id:9,href:'/interview/docs/pl/c/',title:"C",section:"5. 编程语言",content:"C #  更多教程详见：C 学习笔记  基础 #    进阶 #    设计与实现 #  "}),a.add({id:10,href:'/interview/docs/cloud/docker/',title:"Docker",section:"7. 云计算",content:"Docker #  更多内容见：Docker 学习笔记\nentrypoint vs cmd #    格式\n Shell form  实际运行的是 /bin/sh -c 命令  有些镜像没有 shell 程序，无法使用这种方式 从外部发送任何 POSIX 信号到 docker 容器，/bin/sh 命令不会转发消息给实际运行的命令   CMD executable param1 param2 ENTRYPOINT executable param1 param2  会忽略 CMD 或者 docker run 参数 无法覆盖     Exec form  the JSON array format CMD [\u0026quot;executable\u0026quot;,\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;]  如果要使用 Shell 环境变量，必须显示使用 sh 如 CMD [ \u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, \u0026quot;echo $HOME\u0026quot; ]   ENTRYPOINT [\u0026quot;executable\u0026quot;,\u0026quot;param1\u0026quot;,\u0026quot;param2\u0026quot;]  会把 CMD 接到后面作为参数 docker run 可以覆盖：docker run demo --entrypoint cmd   不管是 ENTRYPOINT 还是 CMD 命令，都强烈建议采用 exec 表示法      覆盖\n ENTRYPOINT 或者 CMD 命令会覆盖 base 镜像的 ENTRYPOINT 或者 CMD 命令  如果设置了 ENTRYPOINT 而没有设置 CMD，则 base 镜像的 CMD 也会被置为空   docker run 覆盖  CMD: 比较容易覆盖：docker run demo cmd ENTRYPOINT: 只有 Exec form 可以覆盖：docker run demo --entrypoint cmd      ENTRYPOINT 与 CMD 的最终结果:\n     No ENTRYPOINT ENTRYPOINT exec_entry p1_entry ENTRYPOINT [\u0026ldquo;exec_entry\u0026rdquo;, \u0026ldquo;p1_entry\u0026rdquo;]     No CMD error, not allowed /bin/sh -c exec_entry p1_entry exec_entry p1_entry   CMD [\u0026ldquo;exec_cmd\u0026rdquo;, \u0026ldquo;p1_cmd\u0026rdquo;] exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry exec_cmd p1_cmd   CMD [\u0026ldquo;p1_cmd\u0026rdquo;, \u0026ldquo;p2_cmd\u0026rdquo;] p1_cmd p2_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry p1_cmd p2_cmd   CMD exec_cmd p1_cmd /bin/sh -c exec_cmd p1_cmd /bin/sh -c exec_entry p1_entry exec_entry p1_entry /bin/sh -c exec_cmd p1_cmd      Kubernetes\n 如果容器没有设置 command 和 args，则使用 docker 镜像自带的命令和参数 如果容器设置了 command（不管有没有设置 args），则 docker 镜像自带命令和参数被忽略 如果容器设置了 args，没有设置 command，则 docker 镜像自带的命令会使用该新参数     Docker 与 Kubernetes 中对应的字段名称。\n   描述 Docker 字段名称 Kubernetes 字段名称     容器执行的命令 Entrypoint command   传给命令的参数 Cmd args    参考：为容器设置启动时要执行的命令和参数\n"}),a.add({id:11,href:'/interview/docs/backend/web/go/',title:"Go Web 后端",section:"Web 后端",content:"Go Web 后端 #  Gin #  Beego #  "}),a.add({id:12,href:'/interview/docs/network/http/',title:"HTTP",section:"3. 网络",content:"HTTP #  HTTP 基础 #  HTTP 状态码有哪些？ #   2XX 成功  200 ok（请求成功） 204 no content （请求成功，但是没有结果返回） 206 partial content （客户端请求一部分资源，服务端成功响应，返回一范围资源）   3XX 重定向  301 move permanently （永久性重定向） 302 found （临时性重定向） 303 see other （示由于请求对应的资源存在着另一个 URI，应使用 GET 方法定向获取请求的资源） 304 not modified （表示在客户端采用带条件的访问某资源时，服务端找到了资源，但是这个请求的条件不符合。跟重定向无关） 307 temporary redirect （跟 302 一个意思）   4XX 客户端错误  400 bad request （请求报文存在语法错误） 401 unauthorized （需要认证（第一次返回）或者认证失败（第二次返回）） 403 forbidden （请求被服务器拒绝了） 404 not found （服务器上无法找到请求的资源）   5XX 服务器错误  500 internal server error （服务端执行请求时发生了错误） 503 service unavailable （服务器正在超负载或者停机维护，无法处理请求）    301 和 302 有什么区别？分别适用于什么场景？ #  101， 304， 307 分别是什么？ #  101 协议升级\n主要用于 websocket，也可以用于 http2 的升级。\n304 协商缓存\n浏览器缓存分为强制缓存和协商缓存，优先读取强制缓存。\n强制缓存分为 expires 和 cache-control，而 expires 是一个特定的时间，是比较旧的标准和 cache-control 通常是一个具体的时间长度，比较新，优先级也比较高。\n307 hsts 跳转\n原本的用法是用于让 post 请求的跳转去新的 post 请求，但也用于 hsts 跳转。\nhsts 全称 HTTP 严格传输安全（HTTP Strict Transport Security，縮寫：HSTS），功能是要求浏览器下次访问该站点时使用 https 来访问，而不再需要先是 http 再转 https。这样可以避免 ssl 剥离攻击，即攻击者在用户使用 http 访问的过程中进行攻击，对服务器冒充自己是用户，在攻击者和服务器中使用 https 访问，在用户和服务器中使用 http 访问。\n具体使用方法是在服务器响应头中添加 Strict-Transport-Security，可以设置 max-age\n参考：\n 面试必考之 http 状态码有哪些   HTTP chunk 是什么？解决了什么问题？ #  允许 HTTP 由应用服务器发送给客户端应用的数据可以分成多个部分\nTransfer-Encoding: chunked\n历史上 Transfer-Encoding 支持 多种编码，但是目前最新的规范里，只支持 chunked 编码，即分块编码一种。\n分块传输编码只在 HTTP/1.1 中提供\nchunked 还是给浏览器传输了长度，但是偷偷藏在了报文当中，所以并没有显式地像 content-length 在头部声明\n由一个标明长度为 0 的 chunk 结束\n# body 非空，而且没有 Content-Length chunked = not (request.body is None or \u0026#39;Content-Length\u0026#39; in request.headers) Facebook 为了减少页面的响应时间，发明了一种他们称之为 “BigPipe” 的技术，这个技术的核心原理就是 Http 的 Chunk 编码。 据 Facebook 的测试表明 “BigPipe” 技术使其页面响应时间减少了约 50% （FireFox3.6 除外，用 FireFox3.6 的响应时间减少约 22%）\n参考：\n 为什么在 HTTP 的 chunked 模式下不需要设置长度 HTTP 协议中 chunk 的应用场景？ kubernetes 用 chunked 来实现 watch 机制，实现发布订阅消息的效果   HTTP/1.1 有哪些问题？ #   TCP 连接数限制   问题：对于同一个域名，浏览器最多只能同时创建 6~8 个 TCP 连接 (不同浏览器不一样) 解决：域名分片 技术，其实就是资源分域，将资源放在不同域名下 (比如二级子域名下)  还有问题：每个 TCP 连接本身需要经过 DNS 查询、三步握手、慢启动等，还占用额外的 CPU 和内存    队头阻塞（ Head-of-line blocking 或缩写为 HOL blocking ）   问题：每个 TCP 连接同时只能处理一个请求 - 响应，浏览器按 FIFO 原则处理请求，如果上一个响应没返回，后续请求 - 响应都会受阻。 解决： HTTP 管线化  还有问题：比如第一个响应慢还是会阻塞后续响应、服务器为了按序返回相应需要缓存多个响应占用更多资源、浏览器中途断连重试服务器可能得重新处理多个请求、还有必须客户端 - 代理 - 服务器都支持管线化    Header 内容多，而且每次请求 Header 不会变化太多，没有相应的压缩传输优化方案 为了尽可能减少请求数，需要做合并文件、雪碧图、资源内联等优化工作，但是这无疑造成了单个请求内容变大延迟变高的问题，且内嵌的资源不能有效地使用缓存机制 明文传输不安全  参考：\n HTTP2 详解    HTTP2 #  HTTP2 有哪些特点？ #   二进制分帧层 (Binary Framing Layer)  帧是数据传输的最小单位，以二进制传输代替原本的明文传输，原本的报文消息被划分为更小的数据帧   多路复用 (MultiPlexing) 服务端推送 (Server Push) Header 压缩 (HPACK) 应用层的重置连接 请求优先级设置 流量控制 HTTP/1 的几种优化可以弃用  合并文件、内联资源、雪碧图、域名分片对于 HTTP/2 来说是不必要的，使用 h2 尽可能将资源细粒化，文件分解地尽可能散，不用担心请求数多    参考：\n HTTP2 详解  HTTP2 多路复用是如何实现的？ #    HTTPS #  HTTPS 握手过程 #   TCP 握手 + SSL 握手  参考：\n SSL 延迟有多大？  "}),a.add({id:13,href:'/interview/docs/backend/mq/kafka/',title:"Kafka",section:"消息队列",content:"Kafka #  Kafka 如何实现一致性？ #  "}),a.add({id:14,href:'/interview/docs/backend/db/mysql/',title:"Mysql",section:"数据库",content:"Mysql #  Mysql 有哪些引擎，分别有什么特点？ #   Mysql 配置文件在哪里？ #   Mysql 索引是怎么实现的？ #   Mysql 事务是怎么实现的？ #  begin 命令并不代表事务的开始，事务开始于 begin 命令之后的第一条语句执行的时候。\nbegin; select * from xxx; commit; -- 或者 rollback;  Mysql 事务隔离级别有哪些？ #     隔离级别 脏读 不可重复读 幻读 锁 备注     读未提交（READ UNCOMMITTED） √ √ √ 不加锁    读提交 （READ COMMITTED） × √ √  Oracle 默认   可重复读 （REPEATABLE READ） × × √  Mysql 默认   串行化 （SERIALIZABLE） × × × 共享锁 相当于单线程     可重复读  事务开始时读到的已有数据是什么，在事务提交前的任意时刻，这些数据的值都是一样的。    设置隔离级别\n-- SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE} set global transaction isolation level read committed; 查询当前有多少事务正在运行\nselect * from information_schema.innodb_trx;  可重复读 #  为了实现可重复读，MySQL 采用了 MVVC (多版本并发控制) 的方式\n我们在数据库表中看到的一行记录可能实际上有多个版本，每个版本的记录除了有数据本身外，还要有一个表示版本的字段，记为 row trx_id，而这个字段就是使其产生的事务的 id，事务 ID 记为 transaction id，它在事务开始的时候向事务系统申请，按时间先后顺序递增。\n快照，学名叫做一致性视图，这也是可重复读和不可重复读的关键，\n 读提交是每次执行语句的时候都重新生成一次快照 可重复读是在事务开始的时候生成一个当前事务全局性的快照   MySQL 的可重复读隔离级别其实解决了幻读问题\n读提交解决了脏读问题，行锁解决了并发更新的问题。 并发写问题的解决方式就是行锁，而解决幻读用的是间隙锁， MySQL 把行锁和间隙锁合并在一起，解决了并发写和幻读的问题，这个锁叫做 Next-Key 锁。\n参考：\n MySQL 事务隔离级别和实现原理  \u0026ndash;\n为什么 Oracle 等默认隔离级别是 READ COMMITTED ，而 Mysql 默认隔离级别是 REPEATABLE READ？ #   Mysql 有哪些锁，各自的使用场景是什么？ #      行锁 表锁 页锁     MyISAM  √    BDB  √ √   InnoDB √ √     BDB 已经被 InnoDB 所取代\n  表锁  开销小，加锁快；不会出现死锁；锁定力度大，发生锁冲突概率高，并发度最低   行锁  开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高   页锁  开销和加锁速度介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和行锁之间，并发度一般      共享锁（S） 排他锁（X) 意向共享锁（IS） 意向排他锁（IX）    行锁（Record Locks）  行锁一定是作用在索引上的   间隙锁（Gap Locks）  间隙锁一定是开区间 间隙锁的应用场景包括并发读取、并发更新、并发删除和并发插入 可重复读与串行化才有间隙锁，读未提交与读提交没有间隙锁   临键锁（Next-key Locks）  临键锁是行锁 + 间隙锁，即临键锁是是一个左开右闭的区间 RR 级别下使用 select ... in share mode 或者 select ... for update 语句，那么 InnoDB 会使用临键锁，因而可以防止幻读（读后写的场景）  RR 级别下使用普通的 select 语句，InnoDB 将是快照读，不会使用任何锁，因而还是无法防止幻读。     共享锁 / 排他锁（Shared and Exclusive Locks）  共享锁 / 排他锁都只是行锁，与间隙锁无关 共享锁：select ... in share mode 排他锁：select ... for update 尽管共享锁 / 排他锁是行锁，与间隙锁无关，但一个事务在请求共享锁 / 排他锁时，获取到的结果却可能是行锁，也可能是间隙锁，也可能是临键锁，这取决于数据库的隔离级别以及查询的数据是否存在。   意向共享锁 / 意向排他锁（Intention Shared and Exclusive Locks）  意向共享锁 / 意向排他锁属于表锁 取得意向共享锁 / 意向排他锁是取得共享锁 / 排他锁的前置条件   插入意向锁（Insert Intention Locks）  插入意向锁是一种特殊的间隙锁，该锁只用于并发插入操作 如果说间隙锁锁住的是一个区间，那么插入意向锁锁住的就是一个点   自增锁（Auto-inc Locks）    增：插入意向锁 删改：排他锁 查：共享锁  参考：\n MySQL 常见的七种锁详细介绍   Mysql 什么情况下会出现死锁？ #   在 InnoDB 引擎下，RR (REPEATABLE-READ) 级别，如果多个事务争抢同一个资源，会发生死锁。  next-key lock\n Mysql 如何保证数据一致性？ #   Mysql 主从如何同步？ #  "}),a.add({id:15,href:'/interview/docs/network/tcp/',title:"TCP/UDP/IP",section:"3. 网络",content:"TCP/UDP/IP #  TCP #  "}),a.add({id:16,href:'/interview/docs/frontend/web/',title:"Web 前端",section:"11. 前端与客户端",content:"Web 前端 #  参考 #  poetries/browser-working-principle #  极客时间浏览器工作原理 http://blog.poetries.top/browser-working-principle\n"}),a.add({id:17,href:'/interview/docs/backend/web/',title:"Web 后端",section:"10. 后台",content:"Web 后端 #  当你在浏览器中输入 google.com 并且按下回车之后发生了什么 #  参考：Web 后端学习笔记\n"}),a.add({id:18,href:'/interview/docs/security/web/',title:"Web 安全",section:"13. 安全",content:"Web 安全 #  Web 安全包括哪些内容？ #  "}),a.add({id:19,href:'/interview/docs/security/web/xss/',title:"XSS",section:"Web 安全",content:"XSS #  什么是 XSS，为什么会发生 XSS？ #  Cross-site scripting 跨站脚本 (wiki)\nXSS 发生的原因 #  没有将用户输入的文本进行合适的过滤，就贸然插入到 HTML 中，这很容易造成注入漏洞。 攻击者可以利用漏洞，构造出恶意的代码指令，进而利用恶意代码危害数据安全。\n不仅仅是业务上的 “用户的 UGC 内容” 可以进行注入，包括 URL 上的参数等都可以是攻击的来源。在处理输入时，以下内容都不可信：\n 来自用户的 UGC 信息 来自第三方的链接 URL 参数 POST 参数 Referer （可能来自不可信的来源） Cookie （可能来自其他子域注入）  有哪些 XSS 攻击方法？ #   在 HTML 中内嵌的文本中，恶意内容以 script 标签形成注入。 在内联的 JavaScript 中，拼接的数据突破了原本的限制（字符串，变量，方法名等）。 在标签属性中，恶意内容包含引号，从而突破属性值的限制，注入其他属性或者标签。 在标签的 href、src 等属性中，包含 javascript: 等可执行代码。 在 onload、onerror、onclick 等事件中，注入不受控制代码。 在 style 属性和标签中，包含类似 background-image:url(\u0026quot;javascript:...\u0026quot;); 的代码（新版本浏览器已经可以防范）。 在 style 属性和标签中，包含类似 expression(...) 的 CSS 表达式代码（新版本浏览器已经可以防范）。   如何防止 XSS 攻击？ #  输入过滤 #  输入侧过滤能够在某些情况下解决特定的 XSS 问题，但会引入很大的不确定性和乱码问题。 在防范 XSS 攻击时应避免此类方法。\n当然，对于明确的输入类型，例如数字、URL、电话号码、邮件地址等等内容，进行输入过滤还是必要的。\n纯前端渲染 #  纯前端渲染，把代码和数据分隔开\n纯前端渲染的过程：\n 浏览器先加载一个静态 HTML，此 HTML 中不包含任何跟业务相关的数据。 然后浏览器执行 HTML 中的 JavaScript。 JavaScript 通过 Ajax 加载业务数据，调用 DOM API 更新到页面上。  在纯前端渲染中，我们会明确的告诉浏览器： 下面要设置的内容是文本（.innerText），还是属性（.setAttribute），还是样式（.style）等等。 浏览器不会被轻易的被欺骗，执行预期外的代码了。\n但纯前端渲染还需注意避免 DOM 型 XSS 漏洞（例如 onload 事件和 href 中的 javascript:xxx 等）。\n在很多内部、管理系统中，采用纯前端渲染是非常合适的。 但对于性能要求高，或有 SEO 需求的页面，我们仍然要面对拼接 HTML 的问题。\n对 HTML 做充分转义 #  对插入到页面中的数据进行转义， 通常是把 \u0026amp; \u0026lt; \u0026gt; \u0026quot; ' / 这几个字符转义掉， 确实能起到一定的 XSS 防护作用，但要完善 XSS 防护措施，我们要使用更完善更细致的转义策略。\nHTML 转义是非常复杂的，在不同的情况下要采用不同的转义规则。如果采用了错误的转义规则，很有可能会埋下 XSS 隐患。 应当尽量避免自己写转义库，而应当采用成熟的、业界通用的转义库。\n常用的模板引擎，如 doT.js、ejs、FreeMarker 等， Java 工程里，常用的转义库为 org.owasp.encoder。\n验证 href 的值 #  对于链接跳转，如 \u0026lt;a href=\u0026quot;xxx\u0026quot; 或 location.href=\u0026quot;xxx\u0026quot;，要检验其内容，禁止以 javascript: 开头的链接，和其他非法的 scheme。\n// 根据项目情况进行过滤，禁止掉 \u0026#34;javascript:\u0026#34; 链接、非法 scheme 等 allowSchemes = [\u0026#34;http\u0026#34;, \u0026#34;https\u0026#34;]; valid = isValid(getParameter(\u0026#34;redirect_to\u0026#34;), allowSchemes); if (valid) { \u0026lt;a href=\u0026#34;\u0026lt;%= escapeHTML(getParameter(\u0026#34;redirect_to\u0026#34;))%\u0026gt;\u0026#34;\u0026gt; 跳转... \u0026lt;/a\u0026gt; } else { \u0026lt;a href=\u0026#34;/404\u0026#34;\u0026gt; 跳转... \u0026lt;/a\u0026gt; } 不区分大小写，可以带空格 #   JavaScript 这个关键字不区分大小写： jAvascRipt:alert('XSS') 可以带空格 %20： %20javascript:alert('XSS')   escapeEmbedJSON #  插入 JSON 的地方不能使用 escapeHTML()，因为转义 \u0026quot; 后，JSON 格式会被破坏。\n\u0026lt;script\u0026gt; var initData = \u0026lt;%= data.toJSON() %\u0026gt; \u0026lt;/script\u0026gt; 这样内联 JSON 也是不安全的\n 当 JSON 中包含 U+2028 或 U+2029 这两个字符时，不能作为 JavaScript 的字面量使用，否则会抛出语法错误。 当 JSON 中包含字符串 \u0026lt;/script\u0026gt; 时，当前的 script 标签将会被闭合，后面的字符串内容浏览器会按照 HTML 进行解析；通过增加下一个 \u0026lt;script\u0026gt; 标签等方法就可以完成注入。  \u0026lt;script\u0026gt; // 实现一个 escapeEmbedJSON() 函数，对内联 JSON 进行转义  var initData = \u0026lt;%= escapeEmbedJSON(data.toJSON()) %\u0026gt; \u0026lt;/script\u0026gt;  预防 DOM 型 XSS 攻击 #  在使用 .innerHTML、.outerHTML、document.write() 时要特别小心，不要把不可信的数据作为 HTML 插到页面上， 而应尽量使用 .textContent、.setAttribute() 等。\n如果用 Vue/React 技术栈，并且不使用 v-html/dangerouslySetInnerHTML 功能， 就在前端 render 阶段避免 innerHTML、outerHTML 的 XSS 隐患。\nDOM 中的内联事件监听器，如 location、onclick、onerror、onload、onmouseover 等， \u0026lt;a\u0026gt; 标签的 href 属性， JavaScript 的 eval()、setTimeout()、setInterval() 等， 都能把字符串作为代码运行。\n\u0026lt;!-- 内联事件监听器中包含恶意代码 --\u0026gt; ![](https://awps-assets.meituan.net/mit-x/blog-images-bundle-2018b/3e724ce0.data:image/png,) \u0026lt;!-- 链接内包含恶意代码 --\u0026gt; \u0026lt;a href=\u0026#34;UNTRUSTED\u0026#34;\u0026gt;1\u0026lt;/a\u0026gt; \u0026lt;script\u0026gt; // setTimeout()/setInterval() 中调用恶意代码  setTimeout(\u0026#34;UNTRUSTED\u0026#34;); setInterval(\u0026#34;UNTRUSTED\u0026#34;); // location 调用恶意代码  location.href = \u0026#34;UNTRUSTED\u0026#34;; // eval() 中调用恶意代码  eval(\u0026#34;UNTRUSTED\u0026#34;); \u0026lt;/script\u0026gt;  Content Security Policy #  严格的 CSP 在 XSS 的防范中可以起到以下的作用：\n 禁止加载外域代码，防止复杂的攻击逻辑。 禁止外域提交，网站被攻击后，用户的数据不会泄露到外域。 禁止内联脚本执行（规则较严格，目前发现 GitHub 使用）。 禁止未授权的脚本执行（新特性，Google Map 移动版在使用）。 合理使用上报可以及时发现 XSS，利于尽快修复问题。  输入内容长度控制 #  对于不受信任的输入，都应该限定一个合理的长度。 虽然无法完全防止 XSS 发生，但可以增加 XSS 攻击的难度。\n其他安全措施 #   HTTP-only Cookie: 禁止 JavaScript 读取某些敏感 Cookie，攻击者完成 XSS 注入后也无法窃取此 Cookie。 验证码：防止脚本冒充用户提交危险操作。   XSS 的检测 #  jaVasCript:/*-/*`/*\\`/*\u0026#39;/*\u0026#34;/**/(/* */oNcliCk=alert() )//%0D%0A%0d%0a//\u0026lt;/stYle/\u0026lt;/titLe/\u0026lt;/teXtarEa/\u0026lt;/scRipt/--!\u0026gt;\\x3csVg/\u0026lt;sVg/oNloAd=alert()//\u0026gt;\\x3e 只要在网站的各输入框中提交这个字符串，或者把它拼接到 URL 参数上，就可以进行检测了。\n能够检测到存在于 HTML 属性、HTML 文字内容、HTML 注释、跳转链接、内联 JavaScript 字符串、内联 CSS 样式表等多种上下文中的 XSS 漏洞， 也能检测 eval()、setTimeout()、setInterval()、Function()、innerHTML、document.write() 等 DOM 型 XSS 漏洞， 并且能绕过一些 XSS 过滤器。\n自动扫描工具 #   Arachni Mozilla HTTP Observatory w3af   参考 #   在学习 XSS 前应该学习什么？ 前端安全系列（一）：如何防止 XSS 攻击？  "}),a.add({id:20,href:'/interview/docs/algs/tree/',title:"二叉树",section:"4. 数据结构与算法",content:"二叉树 #  "}),a.add({id:21,href:'/interview/docs/algs/dp/',title:"动态规划",section:"4. 数据结构与算法",content:"动态规划 #  "}),a.add({id:22,href:'/interview/docs/network/send/',title:"发包工具",section:"3. 网络",content:"发包工具 #  综合 #  常用发包工具有哪些？分别有什么特点，适用于什么场景？ #   PacketSender #  "}),a.add({id:23,href:'/interview/docs/others/encode/',title:"字符编码",section:"15. 其他",content:"字符编码 #  有的字符在一些环境中是不能显示或使用的， 比如 \u0026amp;, = 等字符在 URL 被保留为特殊作用的字符； 比如描述一张图片，而图片中的二进制码如果转成对应的字符的话，会有很多不可见字符和控制符（如换行、回车之类）， 这时就需要对进行编码。\n各种编码的特征 #   Base 编码  Base64  组成字符：A-Z、a-z、0-9、+、/ 末尾一般补 0-2 个 =（可以不补 =）   Base32  组成字符：A-Z、2-7 末尾一般补 0-6 个 =（可以不补 =）   Base16  组成字符：0-9、A-F 末尾没有 =       Base 编码 #  参考：rfc4648\nBase 系列的就是用来将字节编码为 ASCII 中的可见字符的。\n在 URL 中使用时必须去掉 “=” 符号\nBase64 #  Base64 编码是使用 64 个可打印 ASCII 字符（A-Z、a-z、0-9、+、/）将任意字节序列数据编码成 ASCII 字符串，另有 “=” 符号用作后缀用途。\nBase64 将输入字符串按字节切分，取得每个字节对应的二进制值（若不足 8 比特则高位补 0）， 然后将这些二进制数值串联起来，再按照 6 比特一组进行切分（因为 2^6=64），最后一组若不足 6 比特则末尾补 0。\n由于二进制数据是按照 8 比特一组进行传输，因此 Base64 按照 6 比特一组切分的二进制数据必须是 24 比特的倍数（6 和 8 的最小公倍数）， 就是 3 个字节。 若原字节序列数据长度不是 3 的倍数时且剩下 1 个输入数据，则在编码结果后加 2 个 =；若剩下 2 个输入数据，则在编码结果后加 1 个 =。\n数据量扩大了 1/3。\nBase32 #  Base16 编码会将字节切为 5 个一组，所以此编码后会用到 32 个字符（A-Z、2-7）， 数据量扩大了 3/5（文本一长，最后填充的 0 和 = 的数据量差不多就可忽略不计了）。\n需要凑够 8 个字符\n00000001 00000011 00000111 00001111 00011111 =\u0026gt; 00000 00100 00001 10000 01110 00011 11000 11111 00000001 00000011 00000111 00001111 00011111 11111111 =\u0026gt; 00000 00100 00001 10000 01110 00011 11000 11111 11111 11100 = = = = = = // 最后不足 5 字节的重组后先在右边充 0，编码完成后再右边充 = 为什么后面要补 = #  由于数据的二进制传输是按照 8 比特一组进行（即一个字节）， 因此 Base32 按 5 比特切分的二进制数据必须是 40 比特的倍数（5 和 8 的最小公倍数），就是 5 字节。\n填充 “=” 符号的作用是方便一些程序的标准化运行，大多数情况下不添加也无关紧要， 而且，在 URL 中使用时必须去掉 “=” 符号。\n优点 #  与 Base64 相比，Base32 具有许多优点：\n 适合不区分大小写的文件系统，更利于人类口语交流或记忆。 结果可以用作文件名，因为它不包含路径分隔符 “/” 等符号。 排除了视觉上容易混淆的字符，因此可以准确的人工录入。 （例如，RFC4648 符号集忽略了数字 “1”、“8” 和 “0”，因为它们可能与字母 “I”，“B” 和 “O” 混淆）。 排除填充符号 “=” 的结果可以包含在 URL 中，而不编码任何字符。  Base32 也比 Base16 有优势：\n Base32 比 Base16 占用的空间更小。（1000 比特数据 Base32 需要 200 个字符，而 Base16 则为 250 个字符）  缺点 #  Base32 比 Base64 多占用大约 20％ 的空间 —— (8/5 - (8/6)) / (8/6)。\n因为 Base32 使用 8 个 ASCII 字符去编码原数据中的 5 个字节数据， 而 Base64 是使用 4 个 ASCII 字符去编码原数据中的 3 个字节数据。\n Base16 #  Base16 编码是一个标准的十六进制字符串（注意是字符串而不是数值），更易被人类和计算机使用， 因为它并不包含任何控制字符，以及 Base64 和 Base32 中的 = 符号。\nBase16 编码会将字节切为 4 个一组，所以此编码后会用到 16 个字符（0-9、A-F），数据会扩大 2 倍\n URL 编码（百分号编码） #   网址路径的编码，用的是 utf-8 编码 查询字符串的编码，用的是操作系统的默认编码 GET 和 POST 方法的编码，用的是网页的编码 Ajax 调用中，IE 总是采用 GB2312 编码（操作系统的默认编码），而 Firefox 总是采用 utf-8 编码  参考：\n 关于 URL 编码   "}),a.add({id:24,href:'/interview/docs/network/capture/',title:"抓包",section:"3. 网络",content:"抓包 #  综合 #  常用抓包工具有哪些？分别有什么特点，适用于什么场景？ #   tcpdump #   tcpdump -D: 列出所有可监听设备 tcpdump -i: 指定网络接口（网卡）  tcpdump -i any: 不确定走哪个网卡   tcpdump host: 指定主机  tcpdump src host: 指定主机发送出去的包 tcpdump dst host: 发送到指定主机的包   tcpdump tcp: 指定协议 tcpdump port: 指定端口 tcpdump -n: 直接显示 IP，而不把 IP 解析为主机名 tcpdump -nn: 直接显示 IP 与端口，而不解析为主机名与服务 tcpdump -N: 不打印 host 的域名部分，比如打印 nic 而不是 nic.ddn.mil tcpdump -w: 输出到文件 tcpdump -tttt: 更具有可读性的时间格式 tcpdump -c: 抓 n 个包，然后退出  # 监视第一个网络接口上所有流过的数据包 tcpdump # 监视指定网络接口的数据包 tcpdump -i eth1 # 截获主机 210.27.48.1 和主机 210.27.48.2 或 210.27.48.3 的通信 tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 \\) # 截获主机 ace 与任何其他主机之间通信的 IP 数据包，但不包括与 helios 之间的数据包 tcpdump ip host ace and not helios # 截获主机 hostname 发送的所有数据 tcpdump -i eth0 src host hostname # 截获所有送到主机 hostname 的数据包 tcpdump -i eth0 dst host hostname # 获取主机 210.27.48.1 接收或发出的 telnet 包 tcpdump tcp port 23 and host 210.27.48.1 # 对本机的 udp 端口 123 进行监视 tcpdump udp port 123 参考：\n A tcpdump Tutorial with Examples — 50 Ways to Isolate Traffic tcpdump 指南 Linux tcpdump 命令详解   wireshark #  "}),a.add({id:25,href:'/interview/docs/algs/sort/',title:"排序算法",section:"4. 数据结构与算法",content:"排序算法 #  "}),a.add({id:26,href:'/interview/docs/backend/db/',title:"数据库",section:"10. 后台",content:"数据库 #  Mysql 与 PostgreSQL 各有什么优势？ #   NoSQL 与传统数据库主要区别是什么？ #   常见的 NoSQL 有哪些，各自适用什么场景？ #  "}),a.add({id:27,href:'/interview/docs/ai/ml/',title:"机器学习",section:"9. 人工智能",content:"机器学习 #  更多内容见：Machine Learning 学习笔记\n"}),a.add({id:28,href:'/interview/docs/algs/search/',title:"查询算法",section:"4. 数据结构与算法",content:"查询算法 #  "}),a.add({id:29,href:'/interview/docs/se/dp/',title:"设计模式",section:"6. 软件工程",content:"设计模式 #  设计原则 #  单一职责原则 (SRP) #   开闭原则 (Open Closed Principle) #   里氏替换原则 (Liskov Substitution Principle) #   依赖倒置原则 (Dependence Inversion Principle) #   接口隔离原则 (Interface Segregation Principle) #   迪米特原则 (Demeter Principle) #    创建型模式 #  简单工厂模式 #   工厂方法模式 #   抽象工厂模式 #   建造者模式 #   单例模式 #    结构型模式 #  适配器模式 #   桥接模式 #   装饰模式 #   外观模式 #   享元模式 #   代理模式 #   组合模式 #  适配器模式、装饰模式、代理模式有哪些异同？ #   适配器模式  适配器模式实现新接口   代理模式  代理模式的特点在于隔离，隔离调用类和被调用类的关系，通过一个代理类去调用。 代理模式是与原对象实现同一个接口 代理模式一定是自身持有这个对象，不需要从外部传入。而装饰模式的一定是从外部传入。   装饰器模式  原有的不能满足现有的需求，对原有的进行增强。 装饰器模式特点在于增强，他的特点是被装饰类和所有的装饰类必须实现同一个接口，而且必须持有被装饰的对象，可以无限装饰。      装饰器模式与代理模式实现原接口 都持有原对象  装饰器模式构造函数接收老对象 适配器模式与代理模式自己 new 老对象    /** * 原接口，需要传入 orderId，时间 */ public interface SourceOrderApi { public void updateDate(String orderId, String date, String client); } public class SourceOrderApiImpl implements SourceOrderApi{ @Override public void updateDate(String orderId, String date, String client) { System.out.println(client+\u0026#34;已将订单\u0026#34;+orderId+\u0026#34;的有效期延长至\u0026#34;+date); } } public class Test { public static void main(String[] args) { SourceOrderApi sourceOrderApi = new SourceOrderApiImpl(); sourceOrderApi.updateDate(\u0026#34;123456\u0026#34;, \u0026#34;2014-10-15\u0026#34;, \u0026#34;user\u0026#34;); } } /** * 适配器模式 */ public interface AppOrderApi { //只需要传入订单Id即可  public void updateDate(String orderId, String client); } public class AppOrderApiImpl implements AppOrderApi{ SourceOrderApi sourceOrderApi; public AppOrderApiImpl(){ sourceOrderApi = new SourceOrderApiImpl(); } @Override public void updateDate(String orderId,String client) { //这里适配的方式随意，但是保证是要完全兼容原有的，就是保证调用原有的接口  sourceOrderApi.updateDate(orderId, \u0026#34;9999-12-31\u0026#34;, client); } } public class Test { public static void main(String[] args) { AppOrderApi appOrderApi = new AppOrderApiImpl(); appOrderApi.updateDate(\u0026#34;123456\u0026#34;, \u0026#34;user\u0026#34;); } } /** * 代理模式 */ public class ProxySourceOrderApiImpl implements SourceOrderApi { SourceOrderApi sourceOrderApi; public ProxySourceOrderApiImpl(){ sourceOrderApi = new SourceOrderApiImpl(); } @Override public void updateDate(String orderId, String date, String client) { //进行判断，如果是admin则更新否则让其输入账号密码  if(\u0026#34;admin\u0026#34;.equals(client)){ sourceOrderApi.updateDate(orderId, date, client); }else{ System.out.println(\u0026#34;账号不是admin，没有查询权限，请输入以admin操作\u0026#34;); } } } /** * 装饰器模式 */ public class NewSourceOrderApiImpl implements SourceOrderApi { SourceOrderApi sourceOrderApi; public NewSourceOrderApiImpl(SourceOrderApi sourceOrderApi){ this.sourceOrderApi = sourceOrderApi; } @Override public void updateDate(String orderId, String date, String client) { sourceOrderApi.updateDate(orderId, date, client); System.out.println(client+\u0026#34;已将订单\u0026#34;+orderId+\u0026#34;的退款期延长至\u0026#34;+date); } }   行为型模式 #  命令模式 #   中介者模式 #   观察者模式 #   状态模式 #   策略模式 #   模板方法模式 #   迭代子模式 #   责任链模式 #   备忘录模式 #   访问者模式 #   解释器模式 #    其他模式 #  并发型模式 #   线程池模式 #  "}),a.add({id:30,href:'/interview/docs/backend/others/hot-load/',title:"配置热加载",section:"其他",content:"配置热加载 #  "}),a.add({id:31,href:'/interview/docs/algs/link/',title:"链表",section:"4. 数据结构与算法",content:"链表 #  "}),a.add({id:32,href:'/interview/docs/pl/cpp/',title:"C++",section:"5. 编程语言",content:"C++ #  更多教程详见：\n C++ 学习笔记 huihut/interview    基础 #    进阶 #    设计与实现 #  "}),a.add({id:33,href:'/interview/docs/security/web/csrf/',title:"CSRF",section:"Web 安全",content:"CSRF #  什么是 CSRF，为什么会发生 CSRF？ #   有哪些 CSRF 攻击方法？ #   如何防止 CSRF 攻击？ #  "}),a.add({id:34,href:'/interview/docs/backend/web/java/',title:"Java Web 后端",section:"Web 后端",content:"Java Web 后端 #  Spring #  "}),a.add({id:35,href:'/interview/docs/cloud/kubernetes/',title:"Kubernetes",section:"7. 云计算",content:"Kubernetes #  更多内容见：Kubernetes 学习笔记\n参考：\n Kubernetes API 资源使用 - 应该使用哪个 Group 和 Version?  端口 #   containerPort：在容器上，用于被 pod 绑定，是可选的，仅仅是提示信息，容器中任何监听 0.0.0.0 的端口，都会暴露出来  是可选的，仅仅是提示信息 容器中任何监听 0.0.0.0 的端口，都会暴露出来 无法被更新    targetPort：在 pod 上，从 port 和 nodePort 上来的流量，经过 kube-proxy 流入到后端 pod 的 targetPort 上，最后进入容器  targetPort 和 containerPort 是一致的  targetPort and containerPort must be identical most of the time because whatever port is open for your application in a container that would be the same port you will wish to send traffic from service via targetPort.\n    port: 负责处理对内的通信，访问方式：clusterIP:port 或者 externalIP:port nodePort:在 node 上，负责对外通信，访问方式：NodeIP:NodePort  参考：\n kubernetes-api/v1.18/ All About Kubernetes Port Types: NodePort,TargetPort,Port,ContainerPort  Service #  Headless Service #  Headless Service 有什么使用场景？\n 第一种：自主选择权，有时候 client 想自己来决定使用哪个 Real Server，可以通过查询 DNS 来获取 Real Server 的信息。 第二种：Headless Services 还有一个用处（PS：也就是我们需要的那个特性）。Headless Service 的对应的每一个 Endpoints，即每一个 Pod，都会有对应的 DNS 域名；这样 Pod 之间就可以互相访问。  "}),a.add({id:36,href:'/interview/docs/backend/db/redis/',title:"Redis",section:"数据库",content:"Redis #  Redis 有哪些数据结构，分别适用什么场景？ #   Redis 数据结构是如何实现的？ #   Redis 如何做持久化？ #  RDB #  在指定的时间间隔能对你的数据进行快照存储\n# 时间策略 save 900 1 save 300 10 save 60 10000 # 文件名称 dbfilename dump.rdb # 文件保存路径 dir /home/work/app/redis/data/ # 如果持久化出错，主进程是否停止写入 stop-writes-on-bgsave-error yes # 是否压缩 rdbcompression yes # 导入时是否检查 rdbchecksum yes AOF #  # 是否开启aof appendonly yes # 文件名称 appendfilename \u0026#34;appendonly.aof\u0026#34; # 同步方式 appendfsync everysec # aof重写期间是否同步 no-appendfsync-on-rewrite no # 重写触发配置 auto-aof-rewrite-percentage 100 auto-aof-rewrite-min-size 64mb # 加载aof时如果有错如何处理 aof-load-truncated yes # 文件重写策略 aof-rewrite-incremental-fsync yes  Redis 是单进程单线程，这么设计有什么优点？ #  "}),a.add({id:37,href:'/interview/docs/backend/mq/rocketmq/',title:"RocketMQ",section:"消息队列",content:"RocketMQ #  "}),a.add({id:38,href:'/interview/docs/others/encryption/',title:"加密",section:"15. 其他",content:"加密 #  SSL/TLS #  TLS 握手流程是什么样的？ #  参考：\n SSL/TLS 详解  "}),a.add({id:39,href:'/interview/docs/se/architecture/',title:"架构设计",section:"6. 软件工程",content:"架构设计 #  架构设计原则 #  CAP (Consistency, Availability, Partition tolerance) #  如何理解 CAP，你在做系统设计时是如何取舍的？ #   ACID (Atomicity, Consistency, Isolation, Durability) #   BASE (Basically Available, Soft state, Eventual consistency) #    高性能 #    高可用 #    高并发 #    高扩展性 #  "}),a.add({id:40,href:'/interview/docs/backend/mq/',title:"消息队列",section:"10. 后台",content:"消息队列 #  常见的消息队列有哪些，分别适用什么场景？ #   RocketMQ 相比于 Kafka 有哪些改进？ #  "}),a.add({id:41,href:'/interview/docs/backend/others/hot-restart/',title:"程序热重启",section:"其他",content:"程序热重启 #  程序如何优雅退出？ #  Linux 信号 #  信号是进程间通信的底层形式。\nLinux 有标准信号 32 个，从 32-63 的信号是实时信号。\n发送信号的原因：\n  硬件异常：如 0 作为除数，内核会发送 SIGFPE（信号值 8）\n  软件异常：如进程终止时，内核会给父进程发送 SIGCHLE（信号值 17），窗口大小调整，应用程序会收到 SIGWINCH（信号值 28）\n  SIGINT 2\n ctrl + C    SIGQUIT 3\n ctrl + \\    SIGKILL 9\n 不可以被阻塞、处理和忽略    SIGTERM 15\n kill 默认不带参数，发送的信号就是 SIGTERM 可以被阻塞、处理和忽略    SIGTOP 20\n 停止（挂起）进程 ctrl + D    Go sigs := make(chan os.Signal, 1) signal.Notify(sigs, syscall.SIGINT, syscall.SIGTERM) fmt.Println(\u0026#34;awaiting signal\u0026#34;) \u0026lt;-sigs fmt.Println(\u0026#34;exiting\u0026#34;) Java Python   如何实现热重启的？ #   服务端启动时多开启一个协程用来监听关闭信号 当协程接收到关闭信号时，将拒绝接收新的连接，并处理好当前所有连接后断开 启动一个新的服务端进程来接管新的连接 关闭当前进程  Go Go 程序优雅关闭与重启 参考：\n gracehttp: 优雅重启 Go 程序（热启动 - Zero Downtime）  Java Python  "}),a.add({id:42,href:'/interview/docs/backend/web/php/',title:"PHP 后端",section:"Web 后端",content:"PHP 后端 #  "}),a.add({id:43,href:'/interview/docs/backend/mq/rabbitmq/',title:"RabbitMQ",section:"消息队列",content:"RabbitMQ #  "}),a.add({id:44,href:'/interview/docs/others/compile/',title:"编译",section:"15. 其他",content:"编译 #  "}),a.add({id:45,href:'/interview/docs/se/pm/',title:"项目管理",section:"6. 软件工程",content:"项目管理 #  "}),a.add({id:46,href:'/interview/docs/frontend/',title:"11. 前端与客户端",section:"Docs",content:"前端与客户端 #  "}),a.add({id:47,href:'/interview/docs/pl/go/',title:"Go",section:"5. 编程语言",content:"Go #  更多教程详见：\n Go 高手进阶 Go 设计与实现 Go 学习笔记 shgopher/GOFamily  geektutu/interview-questions    基础 #  标准库 #  为什么需要 response.Body.Close()？ #  为了 TCP 连接复用\n// The default HTTP client's Transport does not // attempt to reuse HTTP/1.0 or HTTP/1.1 TCP connections // (keep-alive) unless the Body is read to completion and is // closed. 读取 body 并关闭，才会复用 TCP 连接\nfor _, route := range routes { res, err := Request(route.method, ts.URL+route.path) if err != nil { panic(err) } io.Copy(ioutil.Discard, res.Body) res.Body.Close() } 参考：\n 为什么必须手动关闭 resp.Body can\u0026rsquo;t assign requested address 错误解决 Go Http 包解析：为什么需要 response.Body.Close()   你现在使用的是什么版本？最新版本是什么，相对有哪些变化？ #  go 版本管理工具，gvm 如何使用？ #   简单说说 Go 包管理工具的发展历史？ #   Go 1.4 及之前  所有的依赖包都是存放在 GOPATH 下，没有版本控制   Go 1.5 至 Go 1.10  每个项目的根目录下可以有一个 vendor 目录，里面存放了该项目的依赖的包   Go 1.11 至 Go 1.12  默认使用的还是 GOPATH 的管理方式 运行 export GO111MODULE=on，使用 Go Modules   Go 1.13 及之后  默认使用 Go Modules    你用过哪些 Go 包管理工具，说说它们的优缺点？ #    golang/dep   Masterminds/glide   kardianos/govendor   Go Mod 相对之前的版本管理有哪些优点？ #   可以指定版本   Go Mod 如何找到引用的包？ #  一般情况：\n查看 $GOPATH/pkg/mod/\n设置 go mod vendor，使用 go build -mod=vendor 来构建项目时：\n  进阶 #  make, new 有什么区别？ #   make  初始化 设置数组的长度、容量等 返回变量本身   new  只初始化 返回变量的指针    list := new([]int) // 不能对未设置长度的指针执行 append 操作 list = append(list, 1) s1 := []int{1, 2, 3} s2 := []int{4, 5} // 编译错误，s2需要展开 // s1 = append(s1, s2) s1 = append(s1, s2...) fmt.Println(s1)  // The make built-in function allocates and initializes an object of type // slice, map, or chan (only). Like new, the first argument is a type, not a // value. Unlike new, make\u0026#39;s return type is the same as the type of its // argument, not a pointer to it. The specification of the result depends on // the type: //	Slice: The size specifies the length. The capacity of the slice is //	equal to its length. A second integer argument may be provided to //	specify a different capacity; it must be no smaller than the //	length. For example, make([]int, 0, 10) allocates an underlying array //	of size 10 and returns a slice of length 0 and capacity 10 that is //	backed by this underlying array. //	Map: An empty map is allocated with enough space to hold the //	specified number of elements. The size may be omitted, in which case //	a small starting size is allocated. //	Channel: The channel\u0026#39;s buffer is initialized with the specified //	buffer capacity. If zero, or the size is omitted, the channel is //	unbuffered. func make(t Type, size ...IntegerType) Type // The new built-in function allocates memory. The first argument is a type, // not a value, and the value returned is a pointer to a newly // allocated zero value of that type. func new(Type) *Type  panic, recover 是怎么实现的？ #  参考：\n Go 语言 panic 和 recover 的原理   Makefile 语法 #   Go 插件系统 #  Go 1.8 版本开始提供了一个创建共享库的新工具，称为 Plugins.\ngo build -buildmode=plugin\nGo 插件系统的应用场景？ #   通过 plugin 我们可以很方便的对于不同功能加载相应的模块； 针对不同语言 (英文、汉语、德语……) 加载不同的语言 so 文件，进行不同的输出； 编译出的文件给不同的编程语言用 (如：c/java/python/lua 等). 需要加密的核心算法，核心业务逻辑可以可以编译成 plugin 插件 黑客预留的后门 backdoor 可以使用 plugin 函数集动态加载  Go 插件系统是如何实现的？ #  参考：\n Go 插件系统   Goroutine 为什么高效？ #   Goroutine 如何调度？ #  Golang 调度器引入了三个结构来对调度的过程建模：\n G 代表一个 Goroutine； M 代表一个操作系统的线程； Machine P 代表一个 CPU 处理器，通常 P 的数量等于 CPU 核数（GOMAXPROCS）。  三者都在 runtime2.go 中定义，他们之间的关系如下：\n G 需要绑定在 M 上才能运行； M 需要绑定 P 才能运行； 程序中的多个 M 并不会同时都处于执行状态，最多只有 GOMAXPROCS 个 M 在执行。  早期版本的 Golang 是没有 P 的，调度是由 G 与 M 完成。 这样的问题在于每当创建、终止 Goroutine 或者需要调度时，需要一个全局锁来保护调度的相关对象 (sched)。 全局锁严重影响 Goroutine 的并发性能。 (Scalable Go Scheduler)\n通过引入 P，实现了一种叫做 work-stealing 的调度算法：\n 每个 P 维护一个 G 队列； 当一个 G 被创建出来，或者变为可执行状态时，就把他放到 P 的可执行队列中； 当一个 G 执行结束时，P 会从队列中把该 G 取出；如果此时 P 的队列为空，即没有其他 G 可以执行， 就随机选择另外一个 P，从其可执行的 G 队列中偷取一半。  该算法避免了在 Goroutine 调度时使用全局锁。\n 抢占  在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死 在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程   全局 G 队列  在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。    为什么 Go 需要自己实现调度器？ #   Goroutine 的引入是为了方便高并发程序的编写。 一个 Goroutine 在进行阻塞操作（比如系统调用）时，会把当前线程中的其他 Goroutine 移交到其他线程中继续执行， 从而避免了整个程序的阻塞。 由于 Golang 引入了垃圾回收（gc），在执行 gc 时就要求 Goroutine 是停止的。通过自己实现调度器，就可以方便的实现该功能。 通过多个 Goroutine 来实现并发程序，既有异步 IO 的优势，又具有多线程、多进程编写程序的便利性。 引入 Goroutine，也意味着引入了极大的复杂性。一个 Goroutine 既要包含要执行的代码， 又要包含用于执行该代码的栈和 PC、SP 指针。  调度器解决了什么问题？ #    栈管理\n既然每个 Goroutine 都有自己的栈，那么在创建 Goroutine 时，就要同时创建对应的栈。 Goroutine 在执行时，栈空间会不停增长。 栈通常是连续增长的，由于每个进程中的各个线程共享虚拟内存空间，当有多个线程时，就需要为每个线程分配不同起始地址的栈。 这就需要在分配栈之前先预估每个线程栈的大小。如果线程数量非常多，就很容易栈溢出。\n为了解决这个问题，就有了 Split Stacks 技术： 创建栈时，只分配一块比较小的内存，如果进行某次函数调用导致栈空间不足时，就会在其他地方分配一块新的栈空间。 新的空间不需要和老的栈空间连续。函数调用的参数会拷贝到新的栈空间中，接下来的函数执行都在新栈空间中进行。\nGolang 的栈管理方式与此类似，但是为了更高的效率，使用了连续栈 （Golang 连续栈） 实现方式也是先分配一块固定大小的栈，在栈空间不足时，分配一块更大的栈，并把旧的栈全部拷贝到新栈中。 这样避免了 Split Stacks 方法可能导致的频繁内存分配和释放。\n  抢占式调度\nGoroutine 的执行是可以被抢占的。如果一个 Goroutine 一直占用 CPU，长时间没有被调度过， 就会被 runtime 抢占掉，把 CPU 时间交给其他 Goroutine。\n    设计与实现 #  "}),a.add({id:48,href:'/interview/docs/backend/web/python/',title:"Python 后端",section:"Web 后端",content:"Python 后端 #  "}),a.add({id:49,href:'/interview/docs/op/',title:"13. 运维",section:"Docs",content:"运维 #  "}),a.add({id:50,href:'/interview/docs/cloud/native/',title:"Cloud Native",section:"7. 云计算",content:"Cloud Native #  "}),a.add({id:51,href:'/interview/docs/pl/java/',title:"Java",section:"5. 编程语言",content:"Java #  更多教程详见：\n Java 学习笔记 Snailclimb/JavaGuide    基础 #    进阶 #    设计与实现 #  "}),a.add({id:52,href:'/interview/docs/pl/javascript/',title:"JavaScript",section:"5. 编程语言",content:"JavaScript #  更多教程详见：JavaScript 学习笔记  基础 #    进阶 #    设计与实现 #  "}),a.add({id:53,href:'/interview/docs/test/',title:"14. 测试",section:"Docs",content:"测试 #  "}),a.add({id:54,href:'/interview/docs/pl/kotlin/',title:"Kotlin",section:"5. 编程语言",content:"Kotlin #  更多教程详见：Kotlin 学习笔记  基础 #    进阶 #    设计与实现 #  "}),a.add({id:55,href:'/interview/docs/security/',title:"13. 安全",section:"Docs",content:"安全 #  "}),a.add({id:56,href:'/interview/docs/pl/php/',title:"PHP",section:"5. 编程语言",content:"PHP #  更多教程详见：\n PHP 高手进阶 PHP 学习笔记 colinlet/PHP-Interview-QA    基础 #    进阶 #    设计与实现 #  "}),a.add({id:57,href:'/interview/docs/others/',title:"15. 其他",section:"Docs",content:"其他 #  "}),a.add({id:58,href:'/interview/docs/pl/python/',title:"Python",section:"5. 编程语言",content:"Python #  更多教程详见：\n Python 学习笔记 taizilongxu/interview_python  kenwoodjw/python_interview_question    基础 #    进阶 #    设计与实现 #  "}),a.add({id:59,href:'/interview/docs/backend/others/',title:"其他",section:"10. 后台",content:"其他 #  "}),a.add({id:60,href:'/interview/docs/pl/rust/',title:"Rust",section:"5. 编程语言",content:"Rust #  更多教程详见：Rust 学习笔记  基础 #    进阶 #    设计与实现 #  "})})()